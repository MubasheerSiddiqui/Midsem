{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9cd61775",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import text\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import os\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cccdd712",
   "metadata": {},
   "outputs": [],
   "source": [
    "def datalist():\n",
    "    mylist = os.listdir(\"ISL_Dataset_C/\")\n",
    "    ls = []\n",
    "    for x in mylist:\n",
    "        ls.append(os.path.splitext(x)[0])\n",
    "    return ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "38a9b51d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cartoonize(img, ds_factor=4, sketch_mode=False):\n",
    "    img_gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    img_gray = cv2.medianBlur(img_gray, 7)\n",
    "    edges = cv2.Laplacian(img_gray, cv2.CV_8U, ksize=5)\n",
    "    ret, mask = cv2.threshold(edges, 100, 255, cv2.THRESH_BINARY_INV)\n",
    "    if sketch_mode:\n",
    "        return cv2.cvtColor(mask, cv2.COLOR_GRAY2BGR)\n",
    "    img_small = cv2.resize(img, None, fx=1.0/ds_factor, fy=1.0/ds_factor, interpolation=cv2.INTER_AREA)\n",
    "    num_repetitions = 10\n",
    "    sigma_color = 5\n",
    "    sigma_space = 7\n",
    "    size = 5\n",
    "\n",
    "    for i in range(num_repetitions):\n",
    "        img_small = cv2.bilateralFilter(img_small, size, sigma_color, sigma_space)\n",
    "\n",
    "    img_output = cv2.resize(img_small, None, fx=ds_factor, fy=ds_factor, interpolation=cv2.INTER_LINEAR)\n",
    "    dst = np.zeros(img_gray.shape)\n",
    "\n",
    "    dst = cv2.bitwise_and(img_output, img_output, mask=mask)\n",
    "    return dst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7c7d6116",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert(text):\n",
    "    text = text.title()\n",
    "    #print(text)\n",
    "    word_Lemmatized = WordNetLemmatizer()\n",
    "    text = word_Lemmatized.lemmatize(text)\n",
    "    #print(text)\n",
    "    ls = datalist()\n",
    "    #print(ls)\n",
    "    if(text == 'Bye'):\n",
    "        print('Good Bye !!')\n",
    "        exit\n",
    "    elif(text in ls):\n",
    "        cap = cv2.VideoCapture('ISL_Dataset_C/' + text + '.mp4')\n",
    "        if (cap.isOpened()== False): \n",
    "            print(\"Error opening video file\")\n",
    "            exit\n",
    "        while(cap.isOpened()):\n",
    "            ret, frame = cap.read()\n",
    "            if ret == True:\n",
    "                cv2.imshow('Corresponding Video', cartoonize(frame, sketch_mode=False))\n",
    "                if cv2.waitKey(50) & 0xFF == ord('q'):\n",
    "                    break\n",
    "            else: \n",
    "                break\n",
    "        cap.release()\n",
    "        cv2.destroyAllWindows()\n",
    "    else:\n",
    "        print(\"Sorry, currently we don't have the word in our back end !\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e2815df2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter text: \n",
      "England\n"
     ]
    }
   ],
   "source": [
    "print('Enter text: ')\n",
    "text = input()\n",
    "convert(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "031ebdf2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
